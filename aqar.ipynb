{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da91147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"aqar.csv\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0301b",
   "metadata": {},
   "source": [
    "- Use Y-data\n",
    "- try multi layer preceptron(loss-funtion MSE, opt: adamw, Activation: Leaky ReLU)\n",
    "- try a Layered ML model(Use three diffrent ml models, they output to the forth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07504435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944597f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_sqm</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>num_bathrooms</th>\n",
       "      <th>district</th>\n",
       "      <th>city</th>\n",
       "      <th>lift</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>حي النرجس</td>\n",
       "      <td>الرياض</td>\n",
       "      <td>0</td>\n",
       "      <td>1500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>حي الملقا</td>\n",
       "      <td>الرياض</td>\n",
       "      <td>1</td>\n",
       "      <td>13500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>حي دره المنسك</td>\n",
       "      <td>ابها</td>\n",
       "      <td>0</td>\n",
       "      <td>635000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>حي ابها الجديده</td>\n",
       "      <td>ابها</td>\n",
       "      <td>0</td>\n",
       "      <td>510000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>208.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>حي القريقر</td>\n",
       "      <td>ابها</td>\n",
       "      <td>0</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area_sqm  num_bedrooms  num_bathrooms         district    city  lift  \\\n",
       "0     116.0           4.0            3.0        حي النرجس  الرياض     0   \n",
       "1     700.0           7.0            5.0        حي الملقا  الرياض     1   \n",
       "3     215.0           6.0            NaN    حي دره المنسك    ابها     0   \n",
       "4     169.0           5.0            NaN  حي ابها الجديده    ابها     0   \n",
       "5     208.0           6.0            NaN       حي القريقر    ابها     0   \n",
       "\n",
       "        price  \n",
       "0   1500000.0  \n",
       "1  13500000.0  \n",
       "3    635000.0  \n",
       "4    510000.0  \n",
       "5    540000.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_feature_cols=[\"area_sqm\",\"num_bedrooms\",\"num_bathrooms\"]\n",
    "cat_feature_cols=[\"district\",\"city\"]\n",
    "bool_feature_cols=[\"lift\"]\n",
    "\n",
    "df : pd.DataFrame = df[(df['is_rental'] == False) & (df['is_daily_rental'] == False) & (df['sale_type'] != 'rent') & (df['sale_type'] !='daily')].copy()\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "# drop listings of land without buildings\n",
    "df : pd.DataFrame = df[df['category_ga_property_category'] != 'land'].copy()\n",
    "# drop listings of commercial buildings\n",
    "df : pd.DataFrame = df[(df[\"category_ga_listing_type\"]!= \"office\") & (df[\"category_ga_listing_type\"]!=\"store\") & (df[\"category_ga_listing_type\"]!=\"warehouse\") & (df[\"category_ga_listing_type\"]!=\"lounge\")].copy()\n",
    "for bool_col in bool_feature_cols:\n",
    "    df[bool_col] = df[bool_col].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "target_col=[\"price\"]\n",
    "\n",
    "\n",
    "df[num_feature_cols + cat_feature_cols + bool_feature_cols + target_col].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1295a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_feature_cols + cat_feature_cols + bool_feature_cols + target_col].hist(bins=50, figsize=(20,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile Data\n",
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df[num_feature_cols + cat_feature_cols + bool_feature_cols + target_col].copy(), title=\"Aqar Dataset Profiling Report\")\n",
    "profile.to_file(\"aqar_data_profiling_report.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pipe= ColumnTransformer([\n",
    "    (\"num_pipeline\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), num_feature_cols),\n",
    "    (\"cat_pipeline\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]), cat_feature_cols),\n",
    "    (\"bool_pipeline\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    ]), bool_feature_cols)\n",
    "])\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "X = df[num_feature_cols + cat_feature_cols + bool_feature_cols]\n",
    "y = df[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_prepared = pipe.fit_transform(X_train)\n",
    "X_test_prepared = pipe.transform(X_test)\n",
    "X_train_prepared, X_test_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile the preprocessed data (without OHE for better human readability)\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Create a profiling-only pipeline (imputation + scaling, but no OHE)\n",
    "profiling_pipe = ColumnTransformer([\n",
    "    (\"num_pipeline\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), num_feature_cols),\n",
    "    (\"cat_pipeline\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ]), cat_feature_cols),\n",
    "    (\"bool_pipeline\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    ]), bool_feature_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "profiling_pipe.set_output(transform=\"pandas\")\n",
    "\n",
    "# Transform for profiling\n",
    "X_train_for_profiling = profiling_pipe.fit_transform(X_train)\n",
    "X_train_for_profiling['price'] = y_train.values\n",
    "\n",
    "# Generate profile\n",
    "profile_preprocessed = ProfileReport(X_train_for_profiling, title=\"Aqar Preprocessed Data Profiling Report (No OHE)\")\n",
    "profile_preprocessed.to_file(\"aqar_preprocessed_data_profiling_report.html\")\n",
    "print(\"Preprocessed data profiling report saved!\")\n",
    "print(f\"\\nProfiled data shape: {X_train_for_profiling.shape}\")\n",
    "print(\"Categorical columns preserved for easier interpretation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f86954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms of preprocessed features\n",
    "X_train_for_profiling.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='r2',\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test_prepared)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "model= grid_search.best_estimator_\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "print(\"\\nCoefficients:\", grid_search.best_estimator_.coef_)\n",
    "print(\"Intercept:\", grid_search.best_estimator_.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3453f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
    "grid_search.fit(X_train_prepared, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = grid_search.best_estimator_\n",
    "model_rf.fit(X_train_prepared, y_train.values.ravel())\n",
    "y_pred_rf = model_rf.predict(X_test_prepared)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Mean Squared Error: {mse_rf}\")\n",
    "print(f\"Random Forest R^2 Score: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = cross_val_score(model, X_train_prepared, y_train.values.ravel(), cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R^2 scores: {cross_val_scores}\")\n",
    "print(f\"Average Cross-validated R^2 score: {cross_val_scores.mean()}\")\n",
    "\n",
    "cross_val_scores_rf = cross_val_score(model_rf, X_train_prepared, y_train.values.ravel(), cv=5, scoring='r2')\n",
    "print(f\"Random Forest Cross-validated R^2 scores: {cross_val_scores_rf}\")\n",
    "print(f\"Random Forest Average Cross-validated R^2 score: {cross_val_scores_rf.mean()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w3 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
